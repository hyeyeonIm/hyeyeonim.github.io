<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hyeyeon IM</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body data-bs-spy="scroll" data-bs-target="#navbar" data-bs-offset="50">

    <!-- Navigation Bar -->
    <nav id="navbar" class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="#">Hyeyeon IM</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="#projects">Projects</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#skills">Skills</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#contact">Contact Me</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Header Section -->
    <header class="header-section text-center text-white d-flex align-items-center justify-content-center">
        <div class="container">
            <h1 class="display-3 fw-bold">Hyeyeon IM</h1>
            <p class="lead">Building a Better World Through Communication in Robotics</p>
            <a href="https://drive.google.com/file/d/1uZx7fEgBndUuPchfTb7mfoBMMzswJT6x/view?usp=sharing" target="_blank" class="btn btn-warning btn-lg mt-3">Resume</a>
        </div>
    </header>

    <!-- Projects Section -->
<section id="projects" class="py-5 bg-light">
    <div class="container">
        <h2 class="text-center mb-4">Projects</h2>
        <div class="row">
            <!-- Project Card 1 - Carebuddy -->
            <div class="col-md-4 mb-4">
                <div class="card h-100 shadow-sm" data-bs-toggle="modal" data-bs-target="#projectModal1">
                    <img src="./projects/carebuddy.jpeg" class="card-img-top fixed-ratio" alt="Carebuddy: Automatic Air Purifier Robot">
                    <div class="card-body">
                        <h5 class="card-title">Carebuddy: Automatic Air Purifier Robot</h5>
                        <p class="card-text">September 2023 - May 2024</p>
                    </div>
                </div>
            </div>

            <!-- Project Card 2 - Cartographer Automapping -->
            <div class="col-md-4 mb-4">
                <div class="card h-100 shadow-sm" data-bs-toggle="modal" data-bs-target="#projectModal6">
                    <img src="./projects/carto_main.png" class="card-img-top fixed-ratio" alt="Cartographer Automapping">
                    <div class="card-body">
                        <h5 class="card-title">Cartographer Automapping</h5>
                        <p class="card-text">August 2024</p>
                    </div>
                </div>
            </div>

            <!-- Project Card 3 - Collision Prevention System -->
            <div class="col-md-4 mb-4">
                <div class="card h-100 shadow-sm" data-bs-toggle="modal" data-bs-target="#projectModal2">
                    <img src="./projects/LidarCamera.png" class="card-img-top fixed-ratio" alt="Collision Prevention System: LiDAR-Camera Calibration">
                    <div class="card-body">
                        <h5 class="card-title">Collision Prevention System : LiDAR-Camera Calibration</h5>
                        <p class="card-text">August 2024</p>
                    </div>
                </div>
            </div>

            <!-- Project Card 4 - H-mobility Autocar Project -->
            <div class="col-md-4 mb-4">
                <div class="card h-100 shadow-sm" data-bs-toggle="modal" data-bs-target="#projectModal3">
                    <img src="./projects/hmobility.png" class="card-img-top fixed-ratio" alt="H-mobility Autocar Project">
                    <div class="card-body">
                        <h5 class="card-title">H-mobility Autocar Project</h5>
                        <p class="card-text">July 2024</p>
                    </div>
                </div>
            </div>

            <!-- Project Card 5 - Gachigayo -->
            <div class="col-md-4 mb-4">
                <div class="card h-100 shadow-sm" data-bs-toggle="modal" data-bs-target="#projectModal4">
                    <img src="./projects/gotogether.png" class="card-img-top fixed-ratio" alt="Gachigayo: AI Conversation Service">
                    <div class="card-body">
                        <h5 class="card-title">Gachigayo: AI Conversation Service</h5>
                        <p class="card-text">August 2023 - September 2023</p>
                    </div>
                </div>
            </div>

            <!-- Project Card 6 - Isaac Sim Project -->
            <div class="col-md-4 mb-4">
                <div class="card h-100 shadow-sm" data-bs-toggle="modal" data-bs-target="#projectModal5">
                    <img src="./projects/isaacsim.png" class="card-img-top fixed-ratio" alt="Isaac Sim Project">
                    <div class="card-body">
                        <h5 class="card-title">Isaac Sim Project</h5>
                        <p class="card-text">August 2024</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Modal for Carebuddy -->
<div class="modal fade" id="projectModal1" tabindex="-1" aria-labelledby="projectModalLabel1" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel1">Carebuddy</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <!-- Skill Tags -->
                <div class="mb-3 text-center">
                    <span class="badge bg-warning text-dark mx-1">AMR</span>
                    <span class="badge bg-warning text-dark mx-1">LiDAR SLAM</span>
                    <span class="badge bg-warning text-dark mx-1">Python</span>
                    <span class="badge bg-warning text-dark mx-1">Object Detection</span>
                    <span class="badge bg-warning text-dark mx-1">LSTM</span>
                </div>

                <!-- Brief Description -->
                <h5 class="fw-bold mt-4">Brief Description</h5>
                <p>This project focuses on developing a mobile air purifier robot using LiDAR SLAM and an LSTM-based air quality scheduling system, integrated with object detection capabilities to avoid obstacles.</p>

                <!-- Motivation -->
                <h5 class="fw-bold mt-4">Motivation</h5>
                <p>In today’s world, air quality management is crucial, especially in urban environments. This project aims to address this challenge by creating a robot that autonomously purifies the air while navigating around obstacles to ensure optimal functionality in various indoor settings.</p>

                <!-- Environment Section -->
                <h5 class="fw-bold mt-4">Scenario</h5>
                <p>In an indoor home environment, the system automatically identifies the space without user intervention, learns the air quality, and manages the air optimally.</p>
                <p>
                    <strong>Robot Characteristics:</strong>
                    <ul>
                        <li><strong>Robot Model:</strong> Omo R1 Mini</li>
                        <li>Utilizes a low-spec board and 2D LiDAR for mapping, which imposes performance limitations.</li>
                    </ul>
                </p>
                <p>
                    <strong>Risk Analysis:</strong>
                    <ul>
                        <li>
                            <strong>Air Quality Data Learning:</strong>
                            <p>The system needs to continuously learn from incoming air quality data. However, hardware limitations prevent the robot from consistently receiving and processing continuous data streams.</p>
                        </li>
                        <li>
                            <strong>Movement:</strong>
                            <p>Continuous movement is necessary for effective air purification, but the robot's battery life poses a constraint, limiting the duration and extent of its operation.</p>
                        </li>
                    </ul>
                </p>

                <!-- Features and Implementation Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Features and Implementation</h5>

                    <!-- Auto Mapping -->
                    <h6 class="fw-bold">Auto Mapping</h6>
                    <p>Implemented automatic mapping using ROS's gmapping and explore_lite.</p>
                    <p>Due to low-spec hardware, automatic mapping with ROS2 could not be utilized.
                        Instead, automatic mapping was achieved using ROS's gmapping and <code>explore_lite</code> packages.
                        Below is the implementation method of the <code>explore_lite</code> package.
                    </p>
                    <img src="./projects/carebuddy/explore_lite.png" class="project-image mb-3" alt="explore_lite">
                    <p>
                        The automatic mapping feature was implemented by adjusting the path generation parameters through the explore_lite frontier algorithm and tuning the parameters that generate the map based on gmapping's lidar scan data.
                        The following image is the rqt graph of the final automapping implementation on the Omo R1 Mini robot.
                    </p>
                    <img src="./projects/carebuddy/automapping.png" class="project-image mb-3" alt="automapping">

                    <!-- Room Segmentation -->
                    <h6 class="fw-bold">Room Segmentation</h6>
                    <p>Utilized the <code>ipa_room_segmentation</code> package to divide the mapped environment.
                        During this process, the following issues were encountered:
                        <ol>
                            <li>Excessive space segmentation as shown in the first image.</li>
                            <li>Coordinate mismatches of the segmented spaces on the map due to differences in the map's origin.</li>
                        </ol>
                    </p>
                    <!-- 두 이미지를 같은 행에 배치 -->
                    <div class="row">
                        <div class="col-md-6 mb-3">
                            <div class="ratio ratio-4x3"> <!-- 원하는 비율로 변경 가능 -->
                                <img src="./projects/carebuddy/toomuch.png" class="project-image" alt="seg_issue1">
                            </div>
                        </div>
                        <div class="col-md-6 mb-3">
                            <div class="ratio ratio-4x3"> <!-- 원하는 비율로 변경 가능 -->
                                <img src="./projects/carebuddy/origin_issue.png" class="project-image" alt="seg_issue2">
                            </div>
                        </div>
                    </div>
                    <p>
                        To address these issues, the following solutions were implemented:
                        <ol>
                            <li>Removed adjacent points through clustering.</li>
                            <li>Adjusted the origin in the map's YAML file.</li>
                            <li>Used OpenCV to flip and rotate the map itself to align the map coordinates correctly.</li>
                        </ol>
                        Below is the ROOM ID segmentation correctly positioned on the map.
                    </p>
                    <img src="./projects/carebuddy/room_seg.png" class="project-image" alt="room_seg">

                    <!-- Embedded YouTube Video -->
                    <h5 class="fw-bold mt-4">Automapping and Navigation Demonstration</h5>
                    <div class="ratio ratio-16x9">
                        <iframe src="https://www.youtube.com/embed/A8NuGGdWVhk" title="Automapping and Navigation Demonstration" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                    </div>

                    <!-- Air Quality Analysis -->
                    <h6 class="fw-bold">Air Quality Analysis</h6>
                    <p>Collected air quality data using fine dust sensors and created an air quality prediction model using LSTM.</p>
                    <img src="./projects/carebuddy/LSTM.png" class="project-image mb-3" alt="LSTM">

                    <!-- Web Control -->
                    <h6 class="fw-bold">Web Control</h6>
                    <p>
                        Since actual users of the product may not be familiar with Linux, it is necessary to make it user-friendly.
                        Utilized the <code>rosbridge_suite</code> to include a WebSocket server, allowing web browsers to communicate with ROS.
                        <br>
                        <code>roslibjs:</code> Enables web applications to interact with ROS using the rosbridge protocol.<br>
                        <code>ros2djs:</code> Renders spatial information such as robots and maps, and interactively visualizes ROS topics and messages.
                    </p>
                    <img src="./projects/carebuddy/web.png" class="project-image" alt="web">
                </div>

                <!-- Hardware/Software Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Hardware/Software</h5>
                    <img src="./projects/carebuddy/background.png" class="project-image" alt="Hardware/Software">
                </div>

                <!-- Structure Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Structure</h5>
                    <img src="./projects/carebuddy/structure.png" class="project-image" alt="Structure">
                </div>

                <!-- Embedded YouTube Video -->
                <h5 class="fw-bold mt-4">Project Demonstration</h5>
                <div class="ratio ratio-16x9">
                    <iframe src="https://www.youtube.com/embed/uZsxsQaiH3c" title="CareBuddy Demonstration" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
            </div>
        </div>
    </div>
</div>


<!-- Modal for Cartographer AutoMapping -->
<div class="modal fade" id="projectModal6" tabindex="-1" aria-labelledby="projectModalLabel6" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel6">Cartographer AutoMapping</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">                
                <!-- Skill Tags -->
                <div class="mb-3 text-center">
                    <span class="badge bg-warning text-dark mx-1">AMR</span>
                    <span class="badge bg-warning text-dark mx-1">Auto Mapping</span>
                    <span class="badge bg-warning text-dark mx-1">Jetson Nano</span>
                </div>

                <!-- Brief Description -->
                <h5 class="fw-bold mt-4">Brief Description</h5>
                <p>
                    Implemented <strong>automatic mapping</strong> based on <strong>Cartographer</strong> on <strong>Allbot</strong>, utilizing components such as:
                </p>               
                <h5 class="fw-bold mt-4">Motivation</h5>
                <p>
                    Aiming to perform automatic mapping using <strong>Cartographer</strong>, which offers superior performance compared to <strong>Gmapping</strong>.
                </p>
                <!-- Environment Section -->
                <h5 class="fw-bold mt-4">Environment</h5>
                <strong>Robot Characteristics:</strong>
                <ul>
                    <li><strong>Robot Model:</strong> Allbot</li>
                    <li>Relatively heavy and has a short battery life.</li>
                </ul>
                <p>
                    <strong>Risk Analysis:</strong>
                    <ul>
                        <li>
                            <strong>Sensor Utilization:</strong>
                            <p>Although there are various sensors, camera latency occurs on the Jetson Nano.</p>
                        </li>
                    </ul>
                </p>

                <!-- Features and Implementation Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Features and Implementation</h5>

                    <!-- Problem -->
                    <h6 class="fw-bold">Problem</h6>
                    <p>
                        To perform auto mapping in ROS, the published map must be received by explore_lite, but Cartographer does not specifically publish a map.
                        The structure of explore_lite is as follows.
                    </p>
                    <img src="./projects/carebuddy/explore_lite.png" class="project-image mb-3" alt="explore_lite">
                    <p>
                        The Cartographer map is not represented merely with values like EMPTY or UNKNOWN (required by explore_lite) but with various occupancy probability values.
                        The structure of Cartographer is as follows.
                    </p>

                    <img src="./projects/carto_auto/cartographer.png" class="project-image mb-3" alt="cartographer">
                    <h6 class="fw-bold">Solution</h6>
                    <p>Therefore, we plan to solve the problem in the following way:
                        <ol>
                            <li>Publish cmap through <code>/submap_list</code>.</li>
                            <li>Convert the published cmap to a standard map.</li>
                            <li>Apply the frontier algorithm to the converted map to enable Auto Mapping.</li>
                        </ol>
                        In other words, receive the map data from the <code>/cmap</code> topic generated by Cartographer, convert it to the map data format used by Gmapping, and then publish it to the <code>/map</code> topic.
                    </p>
                    <img src="./projects/carto_auto/carto_automapping.png" class="project-image mb-3" alt="carto_automapping">

                    <!-- Embedded YouTube Video -->
                    <h5 class="fw-bold mt-4">Project Demonstration</h5>
                    <div class="ratio ratio-16x9">
                        <iframe src="https://www.youtube.com/embed/tmu-C6UV9_4?si=_0EJdR3AdZx8KScN" title="Cartographer AutoMapping Demonstration" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Modal for LiDAR-Camera Calibration -->
<div class="modal fade" id="projectModal2" tabindex="-1" aria-labelledby="projectModalLabel2" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <!-- Modal Header -->
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel2">LiDAR-Camera Calibration</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>

            <!-- Modal Body -->
            <div class="modal-body">
                <!-- Skill Tags -->
                <div class="mb-4 text-center">
                    <span class="badge bg-warning text-dark mx-1">LiDAR-Camera Calibration</span>
                    <span class="badge bg-warning text-dark mx-1">Object Detection</span>
                    <span class="badge bg-warning text-dark mx-1">Python</span>
                </div>

                <!-- Brief Description -->
                <h5 class="fw-bold mt-4">Brief Description</h5>
                <p>This project focuses on designing an enhanced collision prevention system through precise distance measurements achieved via calibration. Utilized a target-based early fusion method with a checkerboard to perform calibration.</p>

                <!-- Motivation -->
                <h5 class="fw-bold mt-4">Motivation</h5>
                <p>To resolve the distance measurement issues encountered when using LiDAR and Camera independently in the CareBuddy project.</p>

                <!-- Scenario Section -->
                <h5 class="fw-bold mt-4">Scenario</h5>
                <p>
                    <strong>Workflow:</strong> Object Detection through Camera → Distance Measurement via LiDAR and Camera → Display warning messages upon approaching specific distances.
                </p>

                <!-- Risk Analysis -->
                <h5 class="fw-bold mt-4">Risk Analysis</h5>
                <ul>
                    <li>
                        <strong>Air Quality Data Learning:</strong>
                        <p>The system needs to continuously learn from incoming air quality data. However, hardware limitations prevent the robot from consistently receiving and processing continuous data streams.</p>
                    </li>
                    <li>
                        <strong>Movement:</strong>
                        <p>Continuous movement is necessary for effective air purification, but the robot's battery life poses a constraint, limiting the duration and extent of its operation.</p>
                    </li>
                </ul>

                <!-- Calibration & Distance Measurement Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Calibration & Distance Measurement</h5>

                    <!-- Camera Calibration (Intrinsic Parameters) -->
                    <h6 class="fw-bold mt-3">Camera Calibration (Intrinsic Parameters)</h6>
                    
                    <!-- Images in the Same Row -->
                    <div class="row">
                        <div class="col-md-6 mb-3">
                            <img src="./projects/calibration/board_fig.png" class="project-image w-100" alt="Intrinsic Calibration Figure">
                        </div>
                        <div class="col-md-6 mb-3">
                            <img src="./projects/calibration/coner.png" class="project-image w-100" alt="Intrinsic Calibration Corners">
                        </div>
                    </div>

                    <p>
                        <strong>Steps:</strong>
                        <ol>
                            <li><strong>Checkerboard Data Collection:</strong> Collected a total of 32 checkerboard images captured from various angles.</li>
                            <li><strong>Checkerboard Corner Detection:</strong> Utilized OpenCV's <code>findChessboardCorners</code> and <code>cornerSubPix</code> to detect corners in the checkerboard images.</li>
                            <li><strong>Intrinsic Parameter Calculation:</strong> Calculated internal parameters (focal lengths <code>fx</code>, <code>fy</code>, principal point <code>cx</code>, <code>cy</code>, and distortion coefficients) using OpenCV's <code>cv2.calibrateCamera</code> with the collected checkerboard images.</li>
                        </ol>
                    </p>

                    <!-- LiDAR-Camera Point Matching -->
                    <h6 class="fw-bold mt-3">LiDAR-Camera Point Matching</h6>
                    <img src="./projects/calibration/point_matching.png" class="project-image mb-3" alt="LiDAR-Camera Point Matching">
                    <p>
                        <strong>Steps:</strong>
                        <ol>
                            <li><strong>LiDAR Measurement Height Check:</strong> Trimmed the foam board to the LiDAR measurement height (11.5cm) to match LiDAR points with camera image coordinates.</li>
                            <li><strong>Placement:</strong> Attached tape at 11.5cm from the LiDAR-measured edges to facilitate point matching.</li>
                            <li><strong>LiDAR-Camera Point Matching:</strong> Matched LiDAR and Camera points according to the marked areas.</li>
                        </ol>
                    </p>

                    <!-- Extrinsic Parameter Calculation -->
                    <h6 class="fw-bold mt-3">Extrinsic Parameter Calculation</h6>
                    <img src="./projects/calibration/parameter.png" class="project-image mb-3" alt="Extrinsic Parameter Calculation">
                    <p>
                        <strong>Steps:</strong>
                        <ol>
                            <li><code>solvePnP</code>: Calculated the rotation matrix (R) and translation vector (T) between the Camera and LiDAR using LiDAR-Camera matching points.</li>
                            <li><code>Rodrigues Transformation</code>: 
                                <ul>
                                    <li>Converted the rotation vector obtained from <code>cv2.solvePnP</code> into a rotation matrix using Rodrigues transformation.</li>
                                    <li>Constructed the transformation matrix to convert LiDAR coordinates to Camera coordinates:</li>
                                </ul>
                                <p><strong>Transformation Matrix:</strong></p>
                                <pre>
    [[R | T]
    [0 | 1]]
                                </pre>
                                <p>
                                    - <strong>R:</strong> Rotation Matrix<br>
                                    - <strong>T:</strong> Translation Vector
                                </p>
                            </li>
                        </ol>
                    </p>

                    <!-- First Data Overlay -->
                    <h6 class="fw-bold mt-3">First Data Overlay</h6>
                    <img src="./projects/calibration/overlay1.png" class="project-image mb-3" alt="First Data Overlay">
                    <p>
                        <strong>Issue:</strong> An additional line of LiDAR points appeared on the ground.<br>
                        <strong>Solution:</strong>
                        <ol>
                            <li><strong>Adjusted YDLiDAR Launch File Parameters:</strong>
                                <ul>
                                    <li><code>ranges</code>: Distance values detected by the LiDAR sensor.</li>
                                    <li><code>angle_min</code>, <code>angle_max</code>: Range of measurement angles.</li>
                                    <li><code>angle_increment</code>: Increment between angles.</li>
                                </ul>
                                <p><strong>Result</strong> : No change.</p>
                            </li>
                            <li><strong>LiDAR Position Adjustment:</strong>
                                <p>When LiDAR projects onto a flat surface like the ground, reflected signals may be detected slightly off the original point.<br>
                                <strong>Solution</strong> Elevated the LiDAR position to mitigate the issue.</p>
                            </li>
                        </ol>
                    </p>

                    <!-- Data Overlay -->
                    <h6 class="fw-bold mt-3">Data Overlay</h6>
                    <img src="./projects/calibration/overlay2.png" class="project-image mb-3" alt="Data Overlay">
                </div>

                <!-- Object Detection & Distance Measurement Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Object Detection & Distance Measurement</h5>

                    <!-- Object Detection -->
                    <h6 class="fw-bold mt-3">Object Detection</h6>
                    <p>
                        Utilized the YOLOv8 model (<code>yolov8n.pt</code>) from the COCO Dataset via Ultralytics.
                    </p>

                    <!-- LiDAR-Based Distance Measurement -->
                    <h6 class="fw-bold mt-3">LiDAR-Based Distance Measurement</h6>
                    <p>
                        Measured distance based on the front-most LiDAR point of the detected object.
                        <ol>
                            <li>Converted polar coordinates to Cartesian coordinates using filtered distances (<code>ranges</code>) and angles (<code>angles</code>).</li>
                            <li>Calculated Euclidean distance.</li>
                        </ol>
                    </p>

                    <!-- Camera-Based Distance Measurement -->
                    <h6 class="fw-bold mt-3">Camera-Based Distance Measurement</h6>
                    <p>
                        1) <strong>Focal Length Extraction:</strong> Obtained internal parameters through checkerboard calibration.<br>
                        2) <strong>Object Height Measurement in Image:</strong> Measured the height of the detected object in pixels using the bounding box from the YOLO model.<br>
                        3) <strong>Actual Object Height Definition:</strong> Defined the actual height of the teddy bear to be recognized as 0.2m.<br>
                        4) <strong>Distance Calculation:</strong>  
                        <pre>
Distance = (Focal Length * Actual Height) / Bounding Box Height
                        </pre>
                    </p>

                    <!-- Measurement Method Differences Based on Distance -->
                    <h6 class="fw-bold mt-3">Measurement Method Differences Based on Distance</h6>
                    <p>
                        <strong>Issues:</strong>
                        <ol>
                            <li>2D LiDAR can only accurately measure distance if the detected object is parallel.</li>
                            <li>The detection ranges of LiDAR and Camera differ.</li>
                        </ol>
                        <strong>Solutions:</strong>
                        <ol>
                            <li>For distances below 0.2m, objects are not simultaneously detected by both sensors.<br>
                                <strong>Action:</strong> Use Camera-only distance measurement for objects under 0.2m.
                            </li>
                            <li>For distances below 0.5m, average value errors occur.<br>
                                <strong>Action:</strong> Calculate the average only if the error is below 0.05m.
                            </li>
                        </ol>
                    </p>
                </div>

                <!-- Distance Measurement & Collision Prevention System Section -->
                <div class="mt-4">
                    <h5 class="fw-bold">Distance Measurement & Collision Prevention System</h5>
                    <p>
                        1) <strong>0.50m ≤ Object ≤ 0.70m:</strong> When an object is between 0.5m and 0.7m, display "<strong>CAUTION! Object Approaching!</strong>"<br>
                        2) <strong>Object &lt; 0.50m:</strong> When an object is closer than 0.5m, display "<strong>WARNING! Immediate Action Required!</strong>"
                    </p>
                </div>

                <!-- Embedded YouTube Video -->
                <h5 class="fw-bold mt-4">Project Demonstration</h5>
                <div class="ratio ratio-16x9 mb-4">
                    <iframe src="https://www.youtube.com/embed/p3hiAyhQx1o" title="Calibration Demonstration" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Modal for H-mobility Autocar Project -->
<div class="modal fade" id="projectModal3" tabindex="-1" aria-labelledby="projectModalLabel3" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel3">H-mobility Autocar Project</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                    <!-- Skill Tags -->
                    <div class="mb-3 text-center">
                        <span class="badge bg-warning text-dark mx-1">ROS2</span>
                        <span class="badge bg-warning text-dark mx-1">Object Detection</span>
                        <span class="badge bg-warning text-dark mx-1">Motor Control</span>
                        <span class="badge bg-warning text-dark mx-1">LiDAR</span>
                        <span class="badge bg-warning text-dark mx-1">Python</span>
                    </div>
    
                    <!-- Brief Description -->
                    <h5 class="fw-bold mt-4">Brief Description</h5>
                    <p>수집한 차선 데이터를 학습하여 차량의 기울기를 조절하는 제어 알고리즘 설계 및 차선 인식 모델 학습을 수행하였습니다.</p>
    
                    <!-- Motivation -->
                    <h5 class="fw-bold mt-4">Motivation</h5>
                    <p>In today’s world, air quality management is crucial, especially in urban environments. This project aims to address this challenge by creating a robot that autonomously purifies the air while navigating around obstacles to ensure optimal functionality in various indoor settings.</p>
    
                    <!-- Images Section -->
                    <div class="mt-4">
                        <h5 class="fw-bold">Experimental Setup</h5>
                        <img src="path_to_your_image_1.jpg" class="img-fluid mb-3" alt="Carebuddy Image 1">
    
                        <h5 class="fw-bold mt-4">Results</h5>
                        <img src="path_to_your_image_2.jpg" class="img-fluid mb-3" alt="Carebuddy Image 2">
                        <img src="path_to_your_image_3.jpg" class="img-fluid mb-3" alt="Carebuddy Image 3">
                    </div>
            </div>
        </div>
    </div>
</div>

<!-- Modal for 가치가요 -->
<div class="modal fade" id="projectModal4" tabindex="-1" aria-labelledby="projectModalLabel4" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel4">가치가요</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                    <!-- Skill Tags -->
                    <div class="mb-3 text-center">
                        <span class="badge bg-warning text-dark mx-1">Deep Learning</span>
                        <span class="badge bg-warning text-dark mx-1">TensorFlow</span>
                        <span class="badge bg-warning text-dark mx-1">Python</span>
                        <span class="badge bg-warning text-dark mx-1">SLAM</span>
                        <span class="badge bg-warning text-dark mx-1">Object Detection</span>
                    </div>
    
                    <!-- Brief Description -->
                    <h5 class="fw-bold mt-4">Brief Description</h5>
                    <p>AI 기반 대화형 노년층 교통 안내 서비스로 음성 인터페이스를 통해 사용자에게 정보를 제공하였습니다.</p>
    
                    <!-- Motivation -->
                    <h5 class="fw-bold mt-4">Motivation</h5>
                    <p>In today’s world, air quality management is crucial, especially in urban environments. This project aims to address this challenge by creating a robot that autonomously purifies the air while navigating around obstacles to ensure optimal functionality in various indoor settings.</p>
    
                    <!-- Images Section -->
                    <div class="mt-4">
                        <h5 class="fw-bold">Experimental Setup</h5>
                        <img src="path_to_your_image_1.jpg" class="img-fluid mb-3" alt="Carebuddy Image 1">
    
                        <h5 class="fw-bold mt-4">Results</h5>
                        <img src="path_to_your_image_2.jpg" class="img-fluid mb-3" alt="Carebuddy Image 2">
                        <img src="path_to_your_image_3.jpg" class="img-fluid mb-3" alt="Carebuddy Image 3">
                    </div>
            </div>
        </div>
    </div>
</div>
<!-- Modal for Isaac Sim Project -->
<div class="modal fade" id="projectModal5" tabindex="-1" aria-labelledby="projectModalLabel5" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel5">Isaac Sim Project</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                    <!-- Skill Tags -->
                    <div class="mb-3 text-center">
                        <span class="badge bg-warning text-dark mx-1">Omniverse</span>
                        <span class="badge bg-warning text-dark mx-1">Isaac Sim</span>
                        <span class="badge bg-warning text-dark mx-1">Dynamics</span>
                    </div>
    
                    <!-- Brief Description -->
                    <h5 class="fw-bold mt-4">Brief Description</h5>
                    <p>Franka로봇의 physics_step을 설정하여 Pick&Place 하는 환경을 구축.</p>
    
                    <!-- Motivation -->
                    <h5 class="fw-bold mt-4">Motivation</h5>
                    <p>Omniverse Isaac Sim의 시뮬레이션 환경에서 관절 로봇의 physics_step을 구현해보고자</p>
    
                    <!-- Images Section -->
                    <div class="mt-4">
                        <h5 class="fw-bold">Experimental Setup</h5>
                        <img src="path_to_your_image_1.jpg" class="img-fluid mb-3" alt="Carebuddy Image 1">
    
                        <h5 class="fw-bold mt-4">Results</h5>
                        <img src="path_to_your_image_2.jpg" class="img-fluid mb-3" alt="Carebuddy Image 2">
                        <img src="path_to_your_image_3.jpg" class="img-fluid mb-3" alt="Carebuddy Image 3">
                    </div>
            </div>
        </div>
    </div>
</div>

<!-- Modal for 라인트레이서 -->
<div class="modal fade" id="projectModal6" tabindex="-1" aria-labelledby="projectModalLabel6" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="projectModalLabel6">라인트레이서</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p><strong>Project Period:</strong> 2023.09 - 2023.10</p>
                <p>카메라를 통해 차선을 인식하여 자율주행하는 라인트레이서 프로젝트. 카메라로 받은 이미지를 학습하여 차선을 인식.</p>
                    <!-- Skill Tags -->
                    <div class="mb-3 text-center">
                        <span class="badge bg-warning text-dark mx-1">Deep Learning</span>
                        <span class="badge bg-warning text-dark mx-1">TensorFlow</span>
                        <span class="badge bg-warning text-dark mx-1">Python</span>
                        <span class="badge bg-warning text-dark mx-1">SLAM</span>
                        <span class="badge bg-warning text-dark mx-1">Object Detection</span>
                    </div>
    
                    <!-- Brief Description -->
                    <h5 class="fw-bold mt-4">Brief Description</h5>
                    <p>This project focuses on developing a mobile air purifier robot using LiDAR SLAM and LSTM-based air quality scheduling, with object detection capabilities to avoid obstacles.</p>
    
                    <!-- Motivation -->
                    <h5 class="fw-bold mt-4">Motivation</h5>
                    <p>In today’s world, air quality management is crucial, especially in urban environments. This project aims to address this challenge by creating a robot that autonomously purifies the air while navigating around obstacles to ensure optimal functionality in various indoor settings.</p>
    
                    <!-- Images Section -->
                    <div class="mt-4">
                        <h5 class="fw-bold">Experimental Setup</h5>
                        <img src="path_to_your_image_1.jpg" class="img-fluid mb-3" alt="Carebuddy Image 1">
    
                        <h5 class="fw-bold mt-4">Results</h5>
                        <img src="path_to_your_image_2.jpg" class="img-fluid mb-3" alt="Carebuddy Image 2">
                        <img src="path_to_your_image_3.jpg" class="img-fluid mb-3" alt="Carebuddy Image 3">
                    </div>
            </div>
        </div>
    </div>
</div>

    <!-- Skills Section -->
    <section id="skills" class="py-5">
        <div class="container">
            <h2 class="text-center mb-4">Skills</h2>
            <div class="row text-center">
                <div class="col-md-4">
                    <h5>Robotics</h5>
                    <p>ROS, Linux, Git, Isaac Sim, Gazebo, Computer Vision, Machine Learning</p>
                </div>
                <div class="col-md-4">
                    <h5>Programming</h5>
                    <p>C++, Python, MATLAB</p>
                </div>
                <div class="col-md-4">
                    <h5>Mechanical Engineering</h5>
                    <p>AutoCAD, NX</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="py-5 text-center">
        <div class="container">
            <h2>Contact Me</h2>
            <img src="haley.jpeg" class="img-fluid rounded-circle mb-3" alt="Hyeyeon IM" style="width: 200px; height: 200px; object-fit: cover;">
            <p>Hyeyeon IM, Robotics Engineer</p>
            <div>
                <a href="https://github.com/hyeyeonim" target="_blank" class="btn btn-dark me-2">GitHub</a>
                <a href="mailto:hyeyeonim@gmail.com" class="btn btn-dark me-2">Email</a>
                <a href="https://linkedin.com/in/hyeyeonim" target="_blank" class="btn btn-dark">LinkedIn</a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-dark text-white text-center py-3"></footer>

    <!-- Bootstrap JS and Popper.js -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>